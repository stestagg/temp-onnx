contains the implementation of the InferenceSampleApi class, which is responsible for loading an ONNX model and running inference on it. It provides functionality for creating an inference session, executing the inference, and disposing of resources. The directory also includes helper methods for loading the model and input tensor data from embedded resources. Additionally, it includes subdirectories for Android, iOS, Xamarin.Forms, and Maui platforms, each implementing platform-specific functionality and visual representation of the project. The directory also manages the C# implementation of the project's inference functionality.