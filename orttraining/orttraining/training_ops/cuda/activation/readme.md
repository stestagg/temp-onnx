contains the implementation of gradient computation for various activation functions in the CUDA execution provider of the project. It includes files for computing the gradients of Gelu, FastGelu, Relu, Sigmoid, QuickGelu, and Tanh activation functions. The files provide CUDA implementations for the gradient computation, including kernel functions for parallel computation on the GPU. The directory also includes files for specialized implementations of these operations for different data types and Gelu computation modes. Additionally, there are files for computing the gradient of the Gelu activation function with respect to the input tensor, given the gradient of the output tensor.