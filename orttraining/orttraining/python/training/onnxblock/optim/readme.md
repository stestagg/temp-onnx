contains the implementation of the AdamW optimizer and the ClipGradNorm function for training ONNX blocks in the project. It includes the files "__init__.py" and "optim.py". The "__init__.py" file contains the implementation of the AdamW optimizer and the ClipGradNorm function. The "optim.py" file defines two classes, AdamWOptimizer and ClipGradNorm, that are used to build an AdamW optimizer block for an ONNX model. The AdamWOptimizer class adds an AdamWOptimizer node to the model, while the ClipGradNorm class adds a gradient clipping subgraph to the model. The AdamW class combines these two blocks to create an AdamW optimizer model based on the input parameters.