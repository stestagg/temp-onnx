contains code related to transformer models in the project. It includes functionality for exporting and optimizing ONNX models, benchmarking performance, generating test data, and converting models between different formats. The code supports various transformer models such as BERT, GPT-2, T5, and BART, and provides specific optimizations for attention layers, layer normalization, and gelu operations. The directory also includes helper functions for working with input/output types, shape inference, and quantization. Overall, it plays a crucial role in the project's machine learning functionality, enabling model conversion, optimization, and inference using ONNX Runtime.