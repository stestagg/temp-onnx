in the project contains Jupyter Notebooks that provide tutorials and examples for using ONNX Runtime with various models. The notebooks cover different scenarios such as pretraining and finetuning a Bert model using AzureML, performing inference with GPT2 models using ONNX Runtime with IO Binding, loading pretrained Bert models from PyTorch and TensorFlow and converting them to ONNX format, and performing inference using ONNX Runtime on both CPU and GPU. The notebooks include step-by-step instructions, code snippets, and tools for model optimization and performance testing.