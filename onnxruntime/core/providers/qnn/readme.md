covers the functionality of executing quantized neural network models in ONNX Runtime. It includes the implementation of the QNNExecutionProvider class, which inherits from the IExecutionProvider class and provides the necessary functionality for executing quantized models. The code interacts with other parts of the project by including headers, using namespaces, and interacting with classes and functions from various parts of the project, such as the kernel registry, op builders, model wrapper, partitioning utils, session options, and logging macros. 

Directory: onnxruntime/core/providers/qnn/builder
Summary:
The code in this subdirectory covers the functionality of building and managing quantized neural network (QNN) models in the ONNX Runtime project. It includes functions and classes for setting properties of QNN tensors, managing the QNN backend, composing and managing the graph information of a QNN model, providing utility functions and operators for QNN operations, creating and managing QNN graphs, registering and creating op builders for various operations, and building operators for QNN models. The code interacts with other functional areas by interacting with QNN-specific headers, resolving symbols, importing necessary dependencies, obtaining and processing graph information, creating and managing QNN graphs, and building operators for the quantized model.