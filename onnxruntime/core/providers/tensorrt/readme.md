in the project contains the implementation of the TensorRT execution provider for ONNX Runtime. It includes functions for setting dynamic ranges, handling CUDA calls, and loading/saving timing cache files. The directory also defines functions for creating and releasing custom op domains, managing provider options, and initializing/shutting down the provider. Overall, the "tensorrt" directory is responsible for integrating TensorRT into the project and providing optimized execution capabilities for ONNX models.