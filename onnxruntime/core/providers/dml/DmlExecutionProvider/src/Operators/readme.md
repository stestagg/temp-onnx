contains the implementation of various operators for the DML (DirectML) execution provider in the project. These operators perform a wide range of computations and operations on input tensors, such as activation functions, affine operations, attention, batch normalization, bias addition, concatenation, convolution, cropping, element-wise operations, embedding layer normalization, expansion, eye-like matrix creation, fused matrix multiplication, gather, group normalization, instance normalization, layer normalization, local response normalization, LP normalization, matrix multiplication, max unpooling, mean variance normalization, memcpy, multi-head attention, negation, non-zero computation, one-hot encoding, padding, pooling, quantized operations, range creation, reshape, reverse sequence, ROI align, ROI pooling, scatter, shape computation, size computation, skip layer normalization, slicing, space-to-depth, split, tiling, top-k selection, transpose, triangular matrix operations, value scaling, and more. These operators are essential for performing various computations and transformations on tensors in deep learning models. The directory also includes operator registrations and utility functions for operator fusion and activation function mapping.