in the project contains the CUDA implementation of various recurrent neural network (RNN) operators, such as CuDNN RNN, GRU (Gated Recurrent Unit), and LSTM (Long Short-Term Memory). These operators handle different RNN modes (RELU, TANH, LSTM) and support bidirectional RNNs. The code provides functions for setting weight and bias parameters, reorganizing weights, caching weights, and computing the RNN forward inference. It also handles zero-length sequences by masking the output. The directory includes files for registering and defining the operators for different data types and versions of the ONNX specification. Additionally, there is a file that contains the CUDA implementation of various functions used in the RNN module, such as reversing a sequence, reordering bidirectional data, applying a mask to the RNN output, and masking zero sequences.